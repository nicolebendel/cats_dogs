{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VSC nunca me hizo el commit asi que copio pego codigo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "def separar_imagenes(ruta_carpeta):\n",
                "    archivos = os.listdir(ruta_carpeta)\n",
                "    for archivo in archivos:\n",
                "        if archivo.startswith('dog'):\n",
                "            destino = os.path.join(ruta_carpeta, 'dog')\n",
                "        elif archivo.startswith('cat'):\n",
                "            destino = os.path.join(ruta_carpeta, 'cat')\n",
                "        else:\n",
                "            continue\n",
                "\n",
                "        if not os.path.exists(destino):\n",
                "            os.makedirs(destino)\n",
                "\n",
                "        shutil.move(os.path.join(ruta_carpeta, archivo), destino)\n",
                "separar_imagenes('../data/raw/train')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from keras.preprocessing import image \n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "data_dir = '../data/raw/train/'\n",
                "subfolder_dog = os.path.join(data_dir, 'dog')\n",
                "imagenes_perros = os.listdir(subfolder_dog)\n",
                "\n",
                "dog_imagenes = []\n",
                "\n",
                "for i in range(9):\n",
                "    ruta_imagen = os.path.join(subfolder_dog, imagenes_perros[i])\n",
                "    img = image.load_img(ruta_imagen, target_size=(200, 200))\n",
                "    img_array = image.img_to_array(img)\n",
                "    img_array = img_array/255.0  # Normalizar los valores de p√≠xeles\n",
                "    dog_imagenes.append(img_array)\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "\n",
                "for i in range(9):\n",
                "    plt.subplot(3, 3, i+1)\n",
                "    plt.imshow(dog_imagenes[i])\n",
                "    plt.axis('off')\n",
                "    plt.title('Imagen de perro')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = '../data/raw/train/'\n",
                "subfolder_cat = os.path.join(data_dir, 'cat')\n",
                "imagenes_cat = os.listdir(subfolder_cat)\n",
                "\n",
                "cat_imagenes = []\n",
                "\n",
                "for i in range(9):\n",
                "    ruta_imagen = os.path.join(subfolder_cat, imagenes_cat[i])\n",
                "    img = image.load_img(ruta_imagen, target_size=(200, 200))\n",
                "    img_array = image.img_to_array(img)\n",
                "    img_array = img_array/255.0  \n",
                "    cat_imagenes.append(img_array)\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "\n",
                "for i in range(9):\n",
                "    plt.subplot(3, 3, i+1)\n",
                "    plt.imshow(cat_imagenes[i])\n",
                "    plt.axis('off')\n",
                "    plt.title('Imagen de gatos')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "train_dir = '../data/raw/train'\n",
                "test_dir = '../data/raw'\n",
                "image_size= (200,200)\n",
                "\n",
                "datagentrain = ImageDataGenerator()\n",
                "datagentest = ImageDataGenerator()\n",
                "\n",
                "train_data = datagentrain.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size = image_size,\n",
                "    classes=['dog','cat']\n",
                "    )\n",
                "\n",
                "test_data = datagentest.flow_from_directory(\n",
                "    test_dir,\n",
                "    target_size = image_size,\n",
                "    classes=['test1']\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (200,200,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.optimizers import Adam\n",
                "\n",
                "model.compile(optimizer= Adam(learning_rate = 0.001), loss = 'categorical_crossentropy',metrics = [\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.fit(train_data, epochs=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save('../models/modelo.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "checkpoint = ModelCheckpoint(\"../models/vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
                "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=3, verbose=1, mode='auto')\n",
                "history = model.fit(train_data, epochs=3, validation_data=test_data, callbacks=[checkpoint,early], steps_per_epoch=100, validation_steps=10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
